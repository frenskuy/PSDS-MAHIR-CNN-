{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluasi Model**"
      ],
      "metadata": {
        "id": "1dUwRdSV7hF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Confusion Matrix**"
      ],
      "metadata": {
        "id": "40v8X31D7s87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix adalah tabel yang digunakan untuk mengevaluasi kinerja model klasifikasi dengan membandingkan nilai prediksi model dengan nilai aktual/ground truth. Ini sangat berguna pada masalah klasifikasi biner (dua kelas), misalnya “positif” vs “negatif”.\n",
        "\n",
        "Confusion matrix standar untuk kasus biner berbentuk:\n",
        "\n",
        "|                  | Prediksi Positif | Prediksi Negatif |\n",
        "|------------------|------------------|------------------|\n",
        "| **Aktual Positif** | TP (True Positive) | FN (False Negative) |\n",
        "| **Aktual Negatif** | FP (False Positive) | TN (True Negative) |\n",
        "\n",
        "Definisi tiap elemen:\n",
        "\n",
        "- TP: Model memprediksi positif dan benar positif.\n",
        "\n",
        "- TN: Model memprediksi negatif dan benar negatif.\n",
        "\n",
        "- FP: Model memprediksi positif tapi sebenarnya negatif (error tipe I).\n",
        "\n",
        "- FN: Model memprediksi negatif tapi sebenarnya positif (error tipe II).\n"
      ],
      "metadata": {
        "id": "mpT-0vCW7xBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metrik Evaluasi**"
      ],
      "metadata": {
        "id": "UZ3FiVOz8K5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Akurasi (Accuracy)**"
      ],
      "metadata": {
        "id": "8nCxtsO18Q6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi adalah metrik evaluasi yang mengukur seberapa baik model membuat prediksi yang benar dari total prediksi yang dilakukan. Dalam konteks klasifikasi, akurasi memberikan gambaran mengenai seberapa sering model memprediksi kelas yang benar, baik itu kelas positif maupun negatif."
      ],
      "metadata": {
        "id": "tV6fWk5a8nSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy didefinisikan sebagai:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "5Z3dVs7kSJzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dengan mengetahui akurasi, kita dapat menilai sejauh mana model berhasil dalam melakukan klasifikasi. Namun, perlu diingat kembali bahwa akurasi mungkin tidak selalu menjadi metrik terbaik, terutama ketika data tidak seimbang atau ketika ada biaya yang berbeda untuk kesalahan jenis yang berbeda (seperti False Positive dan False Negative). Oleh karena itu, penting untuk mempertimbangkan metrik evaluasi lain seperti presisi, recall, dan F1 score dalam mengukur kinerja model."
      ],
      "metadata": {
        "id": "VaTa3XNdTAoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Presisi (Precision)**\n",
        "\n",
        "Presisi adalah metrik evaluasi yang mengukur seberapa baik model membuat prediksi yang benar untuk kelas positif dari total prediksi positif yang dilakukan. Dalam konteks klasifikasi, presisi memberikan gambaran mengenai seberapa sering model memprediksi kelas positif dengan benar, di antara semua prediksi positif yang dibuat oleh model.\n",
        "\n",
        "Untuk menghitung presisi, kita bisa menggunakan rumus matematika berikut:\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{Precision} = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "Dengan mengetahui presisi, kita dapat menilai sejauh mana model berhasil dalam melakukan klasifikasi yang lebih fokus pada kelas positif dan mengurangi kesalahan jenis False Positive. Namun, perlu diingat bahwa presisi saja mungkin tidak selalu menjadi metrik terbaik, terutama ketika kita perlu mempertimbangkan kinerja model dalam mengklasifikasikan kelas negatif juga. Oleh karena itu, penting untuk mempertimbangkan metrik evaluasi lain seperti recall dan F1 score dalam mengukur kinerja model.\n"
      ],
      "metadata": {
        "id": "_n-axs5mTBgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Sensitivitas (Recall)**\n",
        "\n",
        "Sensitivitas (Recall) adalah metrik evaluasi yang menggambarkan seberapa baik suatu model dalam mengidentifikasi kelas positif dengan benar. Sebagai analogi, bayangkan kita sedang mencari jarum di tumpukan jerami. Recall menggambarkan seberapa baik kita menemukan semua jarum yang ada di tumpukan tersebut. Jika kita menemukan 6 dari 10 dari jarum ditumpukan Jerami tersebut, artinya kita masih melewatkan 4 jarum yang belum ditemukan.\n",
        "\n",
        "Untuk menghitung nilai Recall, kita dapat menggunakan persamaan matematika berikut:\n",
        "\n",
        "$$\n",
        "\\text{Recall} = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "Kelebihan dari Recall adalah bahwa metrik ini fokus pada mengurangi kesalahan False Negative, sehingga kita bisa memastikan bahwa sebanyak mungkin review positif diidentifikasi dengan benar. Namun, perlu diingat bahwa Recall saja mungkin tidak selalu menjadi metrik evaluasi terbaik, terutama ketika kita perlu mempertimbangkan kinerja model dalam mengklasifikasikan kelas negatif juga. Oleh karena itu, penting untuk mempertimbangkan metrik evaluasi lain seperti Presisi dan F1 Score dalam mengukur kinerja model."
      ],
      "metadata": {
        "id": "qg1hcm05Tke-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. F1-Score**\n",
        "\n",
        "F1 Score merupakan metrik evaluasi yang mencerminkan keseimbangan antara Presisi (Precision) dan Sensitivitas (Recall). Nilai F1 Score akan memberikan informasi tentang seberapa baik model kita dalam menggabungkan kemampuan Presisi dan Sensitivitas, sehingga kita bisa memahami seberapa efektif model kita dalam mengklasifikasikan data target secara akurat.\n",
        "\n",
        "Untuk menghitung F1 Score, kita menggunakan rumus matematika berikut:\n",
        "\n",
        "\n",
        "$$\n",
        "\\text{F1-Score} =\n",
        "2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}\n",
        "{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "Kelebihan dari F1 Score adalah metrik ini mempertimbangkan kedua aspek kinerja model (Presisi dan Sensitivitas) dalam satu angka, sehingga kita bisa mendapatkan gambaran yang lebih lengkap tentang kinerja model. Namun, perlu diingat bahwa F1 Score mungkin tidak selalu menjadi metrik evaluasi terbaik dalam semua situasi, terutama jika kita ingin fokus pada kinerja model dalam mengklasifikasikan salah satu kelas saja. Oleh karena itu, penting untuk mempertimbangkan metrik evaluasi lain seperti Presisi dan Sensitivitas dalam mengukur kinerja model."
      ],
      "metadata": {
        "id": "D92qN4ymT7YB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Latihan**"
      ],
      "metadata": {
        "id": "ZVilMIDPZUKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lengkapi kode evaluasi model berikut untuk menghitung akurasi, classification report, dan confusion matrix."
      ],
      "metadata": {
        "id": "rRKtN0DFZ1D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "7oyO155IraFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Dataset dengan Augmentasi untuk Training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "-ft2tTLHoEf5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7eEtoCjoKuC",
        "outputId": "d020ffe0-171d-48d2-e020-783c9e66e5c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 11.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 189kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.60MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0afKH2boLFT",
        "outputId": "1631a05d-6330-4a54-8998-306da801fc30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Setup Training\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    running_loss_train = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss_train += loss.item()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_train_preds.extend(preds.cpu().numpy())\n",
        "        all_train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(all_train_labels, all_train_preds)\n",
        "    avg_loss_train = running_loss_train / len(trainloader)\n",
        "    model.eval()\n",
        "    running_loss_val = 0.0\n",
        "    all_val_preds = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss_val += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_val_preds.extend(preds.cpu().numpy())\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_acc = accuracy_score(all_val_labels, all_val_preds)\n",
        "    avg_loss_val = running_loss_val / len(testloader)\n",
        "    print(f'Epoch [{epoch+1}/5], Loss Train: {avg_loss_train:.4f}, Acc Train: {train_acc:.2%}, '\n",
        "          f'Loss Val: {avg_loss_val:.4f}, Acc Val: {val_acc:.2%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WSJSlR9oQOa",
        "outputId": "66dd8ad1-84bc-491a-8bba-2d51cdc293f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss Train: 0.5333, Acc Train: 80.62%, Loss Val: 0.4223, Acc Val: 85.03%\n",
            "Epoch [2/5], Loss Train: 0.3992, Acc Train: 85.43%, Loss Val: 0.3692, Acc Val: 86.67%\n",
            "Epoch [3/5], Loss Train: 0.3622, Acc Train: 86.89%, Loss Val: 0.3341, Acc Val: 87.31%\n",
            "Epoch [4/5], Loss Train: 0.3420, Acc Train: 87.52%, Loss Val: 0.3386, Acc Val: 87.25%\n",
            "Epoch [5/5], Loss Train: 0.3227, Acc Train: 87.98%, Loss Val: 0.3208, Acc Val: 88.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluasi Model\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# ———————————————————————————————————————————————————————————————\n",
        "# MELENGKAPI EVALUASI MODEL\n",
        "# ———————————————————————————————————————————————————————————————\n",
        "\n",
        "# 1: Menghitung akurasi keseluruhan\n",
        "\n",
        "# lengkapi codingan\n",
        "\n",
        "print(f\"Akurasi Keseluruhan: {acc:.4f}\")\n",
        "\n",
        "# 2: Menampilkan classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# lengkapi codingan\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n",
        "\n",
        "# 3: Menampilkan confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# lengkapi codingan\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "SeZwLli6aJf2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}